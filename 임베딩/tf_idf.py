# 문서에서 특정 단어의 중요도를 계산하는 방법
# bow(문서를 단어의 집합으로 표현/단어의 빈도 기록)에 가중치를 부여 

#%%
#사이킷런을 이용해 벡터화

from sklearn.feature_extraction.text import TfidfVectorizer

corpus = [
    "오늘은 토요일,오늘도 늦게 일어나버렸다.",
    "하지만? 일어나자마자 공부하는 나 자신 매우 칭찬해",
    "오늘은 날씨가 너무 좋아서 등산을 갈 계획이다."
]

tfidf_vectorizer = TfidfVectorizer()
tfidf_vectorizer.fit(corpus)
tfidf_matrix = tfidf_vectorizer.transform(corpus)

print(tfidf_matrix.toarray())
print(tfidf_vectorizer.vocabulary_)

# [[0.         0.         0.         0.         0.46735098 0.
#   0.         0.46735098 0.35543247 0.46735098 0.         0.
#   0.         0.         0.46735098 0.        ]
#  [0.         0.40824829 0.         0.         0.         0.
#   0.40824829 0.         0.         0.         0.40824829 0.40824829
#   0.         0.40824829 0.         0.40824829]
#  [0.42339448 0.         0.42339448 0.42339448 0.         0.42339448
#   0.         0.         0.32200242 0.         0.         0.
#   0.42339448 0.         0.         0.        ]]
# {'오늘은': 8, '토요일': 14, '오늘도': 7, '늦게': 4, '일어나버렸다': 9, '하지만': 15, '일어나자마자': 10, '공부하는': 1, '자신': 11, '매우': 6, '칭찬해': 13, '날씨가': 2, '너무': 3, '좋아서': 12, '등산을': 5, '계획이다': 0}

#해당 값을 이용해 문서마다 중요한 단어만 추출 가능!
#but, 빈도 기반 벡터화는 문장의 순서나 문맥을 보지 않음
# 또한 벡터가 해당 문서 내의 중요도를 의미할 뿐, 단어의 의미를 담고 있지는 않다
